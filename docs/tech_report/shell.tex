\label{shell}

Shellsort is a derivative of insertion sort designed to offer a compromise
between the performance of mergesort and radixsort, and the space efficiency of
selection sort, bubblesort and insertion sort. It was designed by Donald Shell
in 1959, and described in \cite{Shell59}\footnote{Shell describes the former
sorts as ``Merging Pairs'' and ``floating decimal sort'', respectively, and the
latter sorts as ``finding the smallest'', ``interchanging pairs'' and ``sifting'',
respectively.}.

Shell begins by considering the array to be made up of $N/2$ subarrays of
length two, where the elements of the subarray are spaced $N/2$ keys apart.
These subarrays are then sorted using insertion sort. The first iteration will
be a simple exchange, but the keys which are exchanged move across the array by
$N/2$ spaces. The sort then considers $N/4$ arrays, who's elements are spaced
$N/4$ keys apart, which are individually sorted by insertion sort, then $N/8$
and so on. The final iteration will be a standard insertion sort, after which
the array will be sorted. A problem with this implementation is that since the
increments are powers of two, keys with odd indices are not compared with keys
with even indices until the final insertion sort. This can lengthen the final
insertion sort's running time to $O(N^2)$.

Since first published, there has been much discussion about the best
\textit{increments} to use in shellsort. Shell's original sort, described above,
has the increments $N/2$, $N/4$, $N/8$, $N/16$ ........ $1$. \cite{Sedgewick96}
discusses many increments used, and provides code for comparing these. Based on
running the \cc{driver} program\footnote{See
http://www.cs.princeton.edu/\textasciitilde{}rs/shell/}, Gonnet's shellsort was
seen to be the fastest on the authors local machine. As a result, this was used
to test the performance of shellsort. This uses increments which are
five-elevenths of the previous increment.

Two versions of Gonnet's sort were used. The first was taken directly from the
code presented by Sedgewick, and only slightly modified to fit into the
framework used.  The second was modified to reduce the complexity of the loop
bounds, and to remove a sentinel check in the inner loop. Code for
\cc{shellsort} and \cc{improved\_shellsort} is shown in Figures \ref{Shellsort
code} and \ref{Improved Shellsort code}.

\code{Shellsort code}{shellsort.c}
\code{Improved Shellsort code}{improved_shellsort.c}

\section{Results}
\subsection{Test parameters}
The increments in Gonnet's shellsort are $\frac{5}{11}N$, $(\frac{5}{11})^2N$,
$(\frac{5}{11})^3N$ ... $1$;

\subsection{Expected Performance}
Shellsort has been much analysed, and it has been shown that it's complexity is
difficult to prove\footnote{See TODOA, TODOB, TODOC and TODOD.}. The instruction
count and cycle counts are expected to be similar to $O(NlogN)$, as this has
been indicated by previous experient. 


The cache performance of shellsort should be regular. Each subarray is sorted in
turn without reference to the next. Since each element of a subarray is quite
far from its next element, an entire cache line must be loaded for each key,
which will be used once per iteration of the sort across the subarray. If there
are a large number of subarrays, as during the iterations with large increments,
there will be no spatial reuse, and little temporal reuse, so long as the
subarray is large than the cache. Once the increment is small enough that each
subarray fits within the cache (i.e. quickly for L2 cache, and much more slowly
for the L1 cache), then temporal reuse will occur. Once an entire subarray fits
within an eighth of the size of the cache (eight being the number of keys
that fit in a cache line), then spatial reuse will occur aswell.  This reuse
will only occur within a single iteration; once the increment with the next
increment begins, most of the contents of the cache will be invalidated, unless
the entire array fits within the cache.

The branch performance of shellsort should be predictable. There are
$log_{(\frac{11}{5})}N$ iterations, each with $N$ branch misses\footnote{See Section
\ref{insertion is predictable} for a discussion of the properties of insertion
sort.}. It is expected, therefore, that there will be $log_{(\frac{11}{5})}N$ misses per
key.

\subsection{Simulation results}
\plot{shell}{}{}{}{}{}{}

Shellsort's simulation results have the characterist shape and range of an
$O(NlogN)$ sort, albeit, not a very good one. It performs better than a
heapsort, but considerably worse than quicksort. However, it easier to program
than either of these two sort.

Shellsort performs roughly double the number of branches and instructions of
quicksort, and has more than twice as many branch mispredictions and nearly
four times as many cache misses. It's cycle count is over three times that of
quicksort, though it is more than 50 percent faster than the best of the
heapsorts.a

%TODO
TODO are there log5_11 N misses
Regenerate data before looking at this

\section{Predictor results}

\sixplot{shellsort_0.eps}{improved_shellsort_0.eps}{}{}{}{}{Shellsorts}

In shellsort, almost exactly half of the important branches are mispredicted.
Simply predicting that all branches are taken would result in a slightly higher
prediction ratio of 50.8\%. Similarly, for improved shellsort, slightly more
than half of the branches are correctly predicted, at 50.3\%, rising to 53\%
using a strategy of predicting all branches as taken.

The results also show that in shellsort, a key moves only 1.03 places down the
array, on average, during each iteration. In improved shellsort, each key moves
over 1.07\% places each iteration, which in the final insertion sort, each key
moves an average of 2.1 places.

The expected number of branch mispredictions is $log_{(\frac{11}{5})}N$. In
actual fact, it is almost exactly correct, being slightly lower (18.48
mispredictions per key, instead of 19.34, for 4194304 keys).


\section{Future Work}
Only Gonnet's way of producing increments is measured here. Using different
increments and different schemes for generating increments would produce
different results. 
