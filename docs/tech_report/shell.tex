\label{shell}

Shellsort is a derivative of insertion sort designed to offer a compromise
between the performance of mergesort and radixsort, and the space efficiency of
selection sort, bubblesort and insertion sort. It was designed by Donald Shell
in 1959, and described in \cite{Shell59}\footnote{Shell describes the former
sorts as \n{Merging Pairs} and \n{Floating Decimal Sort}, respectively, and the
latter sorts as \n{Finding the Smallest}, \n{Interchanging Pairs} and
\n{Sifting}, respectively.}.

Shell begins by considering the array to be made up of $\frac{N}{2}$ sub-arrays
of length two, where the elements of the sub-array are spaced $\frac{N}{2}$ keys
apart.  These sub-arrays are then sorted using insertion sort. The first
iteration will be a simple exchange, but the keys which are exchanged move
across the array by $\frac{N}{2}$ spaces. The sort then considers $\frac{N}{4}$
arrays, whose elements are spaced $\frac{N}{4}$ keys apart, which are
individually sorted by insertion sort, then $\frac{N}{8}$ and so on. The final
iteration will be a standard insertion sort, after which the array will be
sorted. A problem with this implementation is that since the increments are
powers of two, keys with odd indices are not compared with keys with even
indices until the final insertion sort. This can lengthen the final insertion
sort's running time to $O(N^2)$.

Since first published, there has been much discussion about the best
\n{increments} to use in shellsort. Shell's original sort, described above,
has the increments $\frac{N}{2}$, $\frac{N}{4}$, $\frac{N}{8}$, $\frac{N}{16}$
........ $1$. \cite{Sedgewick96} discusses many increments used, and provides
code for comparing these. Based on running the \cc{driver} program\footnote{See
http://www.cs.princeton.edu/\textasciitilde{}rs/shell/}, Gonnet's shellsort was
seen to be the fastest on the authors local machine. As a result, this was used
to test the performance of shellsort. This uses increments which are
$\frac{5}{11}^{th}s$ of the previous increment.

Two versions of Gonnet's sort were used. The first was taken directly from the
code presented by Sedgewick, and only slightly modified to fit into the
framework used.  The second was modified to reduce the complexity of the loop
bounds, and to remove a sentinel check in the inner loop. Code for shellsort and
improved shellsort is shown in Figures \ref{Shellsort code} and \ref{Improved
shellsort code}.

\code{Shellsort code}{shellsort.c}
\code{Improved shellsort code}{improved_shellsort.c}

\section{Results}
\subsection{Test Parameters}
The increments in Gonnet's shellsort are $\frac{5}{11}N$, $(\frac{5}{11})^2N$,
$(\frac{5}{11})^3N$ ... $1$;

\subsection{Expected Performance}
Shellsort is designed to perform similarly to an $O(NlogN)$ sort. The instruction
count and cycle counts are therefore expected to be similar to $O(NlogN)$.

The cache performance of shellsort should be regular. Each sub-array is sorted in
turn without reference to the next. Since each element of a sub-array is quite
far from its next element, an entire cache line must be loaded for each key,
which will be used once per iteration of the sort across the sub-array. If there
are a large number of sub-arrays, as during the iterations with large increments,
there will be no spatial reuse, and little temporal reuse, so long as the
sub-array is large than the cache. Once the increment is small enough that each
sub-array fits within the cache (i.e. quickly for L2 cache, and much more slowly
for the L1 cache), then temporal reuse will occur. Once an entire sub-array fits
within an eighth of the size of the cache (eight being the number of keys
that fit in a cache line), then spatial reuse will occur as well.  This reuse
will only occur within a single iteration; once the increment with the next
increment begins, most of the contents of the cache will be invalidated, unless
the entire array fits within the cache.

The branch performance of shellsort should be predictable. There are
$log_{(\frac{11}{5})}N$ iterations, each with $N$ branch misses\footnote{See Section
\ref{insertion is predictable} for a discussion of the properties of insertion
sort.}. It is expected, therefore, that there will be $log_{(\frac{11}{5})}N$ misses per
key.

Improved shellsort should have a slightly lower instruction count, and hence a
lower cycle count, than shellsort. It's cache performance should be the same,
and it should have the same number of comparative branches, and hence a similar
number of mispredictions, though its branch count should be higher than
shellsort.


\subsection{Simulation Results}
\plot{shell}{}{}{}{}{}{}

Shellsort's simulation results have the characteristic shape and range of an
$O(NlogN)$ sort, albeit, not a very good one. The slopes of its graphs are
slightly steeper, as can be seen in Figures \ref{shell cycles}, \ref{shell
instructions}, \ref{shell level 1 misses} and \ref{shell branch misses}. It
performs better than a heapsort, but considerably worse than quicksort. However,
it easier to program than either of these two sorts.

Shellsort performs roughly double the number of branches and instructions of
quicksort, and has more than twice as many branch mispredictions and nearly
four times as many cache misses. It's cycle count is over three times that of
quicksort, though it is more than 50 percent faster than the best of the
heapsorts.

Shellsort's cache misses are certainly in the range of an $O(NlogN)$ sort, and
are not considerably worse than memory-tuned heapsort, and are in fact better
than base heapsort. This occurs without any cache improvements being performed
upon them.  Shellsort's branch mispredictions, are, as predicted
$O(Nlog_{\frac{5}{11}}N)$. 

Improved shellsort does improve on shellsort, having approximately 10\% fewer
instructions. It also has slightly fewer cache misses and branch mispredictions.
Overall, this leads to a reduction in cycle count of between 35 and 70\%, as
seen in Figure \ref{shell cycles}.

%TODO
\section{A More Detailed Look at Branch Prediction}

\sixplot{shellsort_0.eps}{improved_shellsort_0.eps}{}{}{}{}{Shellsorts}

%TODO see figure something
In shellsort, almost exactly half of the important branches are mispredicted.
Simply predicting that all branches are taken would result in a slightly higher
prediction ratio of 50.8\%. Similarly, for improved shellsort, slightly more
than half of the branches are correctly predicted, at 50.3\%, rising to 53\%
using a strategy of predicting all branches as taken. These results can be seen
in Figures \ref{Branch prediction performance for Shellsorts}.

The results also show that in shellsort, a key moves only 1.03 places down the
array, on average, during each iteration. In improved shellsort, each key moves
over 1.07\% places each iteration, which in the final insertion sort, each key
moves an average of 2.1 places.

The expected number of branch mispredictions is $log_{(\frac{11}{5})}N$.  This
is almost exactly correct, being slightly lower (18.48 mispredictions per key,
instead of 19.34, for 4194304 keys).


\section{Future Work}
Only Gonnet's way of producing increments is measured here. Using different
increments and different schemes for generating increments would produce
different results. 
