Intro:

One of the sorts used by lamarca is the heap sort. He dedicates a whole chapter
to heaps and stategies to improve their performace in the cache. First we need
someting to compare it to, and for this he optimises a heapsort for
instructions. Our base version ran at about x for data size N, and the latest
version did y.

Heaps
A heap is a specific type of binary tree, where each item has the heap property.
Typically, the heap property means that each child node of a binary tree has a
lower value than its parent, but the opposite is also a valid heap.

Indexing
A heap tree has an interesting property which is not shared by other types of
binary trees, and that is that it is full. Each level of the tree, except the
lowest, is full, and the lowest is filled from left to right. This means that a
heap tree will fit into an array of the same size.
An array that is indexed from 1 to N can be thought of as a heap where a node
indexed i has a parent indexed floor(i/2), and 2 children indexed i*2 and
i*2+1.  These operations are simple on any machine, and can be substituted with
i << 1 and i >> 1.
In C, arrays are indexed from 0 - N-1, breaking this indexing scheme. This can
be fixed by using a pointer to a[-1] instead of a. Hence the index 1 is a[-1+1],
and N indexes a[N-1]

Constructing a Heap (heapifying)
There are two methods to construct a heap, fixing up and fixing down. These are
also used to maintained the heap property after adding or removing items. For
this explanation we shall assume that the heap property is that a parent is
larger than its children.
Fix-up (sift up)
Sifting an item up means comparing it with its parent, and swapping it if it is
larger. This continues up the heap until 
Fix-down (sift down)

O(NlogN)
A heap has two 
Creating the heap is cheap relative the the second part. This takes N/2*(logN-1)
steps. In the second part, there are logN swaps and comparisons in a fix down,
which occurs nearly N times.  This means a near constant ONlogN, with only a
slightly slower pathalogical case.

Floyds Improvement
Floyd observed, as we will shortly, that when sifting a small item down the
heap, it goes nearly the whole way down, before making its way slowly back up.
We can avoid half the comparisons on the way down with this method. Sedgewick
notes that this is a good idea when comparisons are expensive relative to
exchanges. He notes that string comparisons are more expensive than string
exchanges (which simply comprise pointer copies). In our case of using unsigned
ints, this approach is not obviously better.
Lamarca however refers to the in place sorting method as Floyds approach.

Sorting with Heaps
Because of the heap property, a properly constructed heap will either have the
largest or the smallest item on the top. This leads to 2 ways of sorting. Both
begin by constructing a heap, followed by removing the top element and putting
it in its final position. There is an in-place method and an out of place.

In place
In this in place sort we use a top heavy heap. The heap is construted by fixing
down from the first item with a child. Once the heap in contructed, we
exchange the first item, the largest item, with the last, which is quite
relatively small. The large item is in its final position, and we reduce the
size of the heap (ie pretend its not there). We then sift the small item down the
heap, and repeat the process for all items.

Out of place
For this we use a heap with smaller items on top. The heap is constructed using
the 'Repeated Adds' method, where an item is added to the bottom of the heap,
then sifted up to fix the heap, then the process repeated for all items. Once
the heap is constructed,  the smallest item is moved to array for sorting, the
item at the end is moved to the top, then sifted down the heap. This is repeated
for all items.

How does Lamarca do it?

Whats wrong with this?

Why does he advocate this way?

Whats the performance/

What did you add?

Which directnio is it made in?

Talk some performance
